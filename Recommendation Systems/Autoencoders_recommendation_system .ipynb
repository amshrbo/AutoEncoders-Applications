{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a recommendation system with Stacked Auto Encoderes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's the famous movie lens dataset you can read more about it [here](https://grouplens.org/datasets/movielens/).\n",
    "- Here I'm gonna use the 100k old version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training dataset and convert it to numpy array\n",
    "training_set_df = pd.read_csv('dataset/ml-100k/u1.base', delimiter = '\\t')\n",
    "trainin_set = np.array(training_set_df, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        1,        16,         5, 878543541])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainin_set[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as shown above the first coulnm refers to the userID, the second one to movieId , the third to the movie rating and the last one refers to time that the user gives the movie the rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        1,        36,         2, 875073180])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the test dataset and convert it to numpy array\n",
    "test_set_df = pd.read_csv('dataset/ml-100k/u1.test', delimiter='\\t')\n",
    "test_set = np.array(test_set_df, dtype=int)\n",
    "test_set[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data will be a giant matrix each row of the matrix represent a user and its rating\n",
    "    > e.g: the first row represent the first user, and the first coulmn in the first row represent the rating from the first user to the first movie\n",
    "    \n",
    "    > e.g: matrix[5, 28] -> that will give us the rating from the user number \\#5 to the movie \\#28\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the max user_id, and the max movie_id\n",
    "    > two know what will be the dimensions of our matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to get total number of users and the same for movies movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cell below, We are taking the maximum number from both the test set and the trainning set because the they are randomly suffeled for both the user and  the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(trainin_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(trainin_set[:, 1]), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users 943, The number of movies 1682\n"
     ]
    }
   ],
   "source": [
    "# printing the results\n",
    "print(f'The number of users {nb_users}, The number of movies {nb_movies}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- List of User 1: [Ratings of all the movies by User 1]\n",
    "- List of User 2: [Ratings of all the movies by User 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Define a function to use it to convert both of the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the below function some points to explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what we are trying to do here is to make a list of lists and every list correspond to a specific user and every element in the list correspondse to the specific movie  \n",
    "\n",
    "- first we are creating an empty list\n",
    "- then loop in range of the number of users in our data and in every step we create a list of length of the number of movies and every value will represent a rate for that movie.\n",
    "- For every user that didn't rate a movie we will put a zero on that element\n",
    "- and for every rate we put it in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fn(data):\n",
    "    converted_data = []\n",
    "    \n",
    "    for user_id in range(1, nb_users + 1):\n",
    "        # getting all the movies ids that rated by every user\n",
    "        movies_for_user_id = data[:, 1][data[:, 0] == user_id] # getting the movies ids that taken be the current user in the for loop\n",
    "        rating_for_user_id = data[:, 2][data[:, 0] == user_id]\n",
    "        \n",
    "        ratings = np.zeros(nb_movies) # initialze all the ratings with zeros then include the rated movies\n",
    "        ratings[movies_for_user_id - 1] = rating_for_user_id\n",
    "        converted_data.append(list(ratings))\n",
    "        \n",
    "    return converted_data        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To chk if our function working let's print some data to get some intuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is the rating value:3, for the movie numeber:2 from the user number:1\n",
      "That is the rating value:4, for the movie numeber:3 from the user number:1\n",
      "That is the rating value:3, for the movie numeber:4 from the user number:1\n"
     ]
    }
   ],
   "source": [
    "print(f'That is the rating value:{trainin_set[0, 2]}, for the movie numeber:{trainin_set[0, 1]} from the user number:{trainin_set[0, 0]}')\n",
    "print(f'That is the rating value:{trainin_set[1, 2]}, for the movie numeber:{trainin_set[1, 1]} from the user number:{trainin_set[1, 0]}')\n",
    "print(f'That is the rating value:{trainin_set[2, 2]}, for the movie numeber:{trainin_set[2, 1]} from the user number:{trainin_set[2, 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ituations from the previous prints:\n",
    "- the user didn't rate movie \\#1 as the first row represent the movie \\#2\n",
    "    - So the first element in the first list should be 0\n",
    "- the begging of the first list should look like this \\[0, 3, 4, 3...\\]\n",
    "- so let's convert them and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training = convert_fn(trainin_set)\n",
    "new_test = convert_fn(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first **list** from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 3.0, 4.0, 3.0, 3.0, 0.0, 4.0, 1.0, 5.0, 0.0]\n",
      "\n",
      "The dimensions of the data is 943 X 1682\n"
     ]
    }
   ],
   "source": [
    "print(new_training[0][:10]) #printing the first ten elemnts in the first list\n",
    "print(f'\\nThe dimensions of the data is {len(new_training)} X {len(new_training[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we expected the first four values are true and the dimensions are good\n",
    "- So we good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data into torch tesnors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = torch.FloatTensor(new_training)\n",
    "test_d = torch.FloatTensor(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Stack auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm using a 6 fully connected layers to make the stacked auto-encoder\n",
    "- form fc1 to fc3 represent the encoder \n",
    "- form fc4 to fc6 represent the decoder \n",
    "- Using the sigmoid activation function between layers\n",
    "    > Using sigmoid after tuning the model as it gives the better results over tanh and relu\n",
    "- Don't use an activation function in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(torch.nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__() # getting all the functionality from the parent class\n",
    "        self.fc1 = torch.nn.Linear(nb_movies, 30) # Encoding\n",
    "        self.fc2 = torch.nn.Linear(30, 15) # Encoding\n",
    "        self.fc3 = torch.nn.Linear(15, 10) # Encoding\n",
    "        self.fc4 = torch.nn.Linear(10, 15) # Decoding\n",
    "        self.fc5 = torch.nn.Linear(15, 30) # Decoding\n",
    "        self.fc6 = torch.nn.Linear(30, nb_movies) # Decoding\n",
    "        \n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        lyr_1 = self.activation(self.fc1(input))\n",
    "        lyr_2 = self.activation(self.fc2(lyr_1))\n",
    "        lyr_3 = self.activation(self.fc3(lyr_2))\n",
    "        lyr_4 = self.activation(self.fc4(lyr_3))\n",
    "        lyr_5 = self.activation(self.fc5(lyr_4))\n",
    "        out = self.fc6(lyr_5)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our cost and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our model over 50 epochs give us an average loss of approxomatily 1.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num: 10, Loss value is: 1.0236103534698486\n",
      "Epoch num: 20, Loss value is: 1.020880937576294\n",
      "Epoch num: 30, Loss value is: 1.0180864334106445\n",
      "Epoch num: 40, Loss value is: 1.0165773630142212\n",
      "Epoch num: 50, Loss value is: 1.0112740993499756\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 50\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    train_loss = 0\n",
    "    nb_usr_rated = 0.0 # to get the mean loss of all the users\n",
    "    \n",
    "    for id_user in range(nb_users):\n",
    "        input_batch = training_d[id_user] # our input batch here is just an example at a time\n",
    "        #torch requirement: taking a batch so we add one extra dimension\n",
    "        input_batch = torch.autograd.Variable(input_batch).unsqueeze(0) \n",
    "        target = input_batch.clone()\n",
    "        # For memeory optimization, We're gonna try to avoid users that didn't rate any movie\n",
    "        if torch.sum(target.data > 0) > 0: # Avoiding users who didn't rate\n",
    "            out = sae(input_batch)\n",
    "            target.require_grad = False # to avoid get gradient for the targets\n",
    "            out[target == 0] = 0\n",
    "            \n",
    "            loss = criterion(out, target)\n",
    "            mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)  \n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
    "            \n",
    "            nb_usr_rated += 1\n",
    "            optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch num: {epoch}, Loss value is: {(train_loss / nb_usr_rated)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing data loss value is: 1.015864610671997\n"
     ]
    }
   ],
   "source": [
    "testing_loss = 0\n",
    "nb_usr_rated = 0.0 # to get the mean loss of all the users\n",
    "    \n",
    "for id_user in range(nb_users):\n",
    "    input_batch = torch.autograd.Variable(training_d[id_user]).unsqueeze(0) \n",
    "    target = torch.autograd.Variable(test_d[id_user]).unsqueeze(0)\n",
    "    # For memeory optimization, We're gonna try to avoid users that didn't rate any movie\n",
    "    if torch.sum(target.data > 0) > 0: # Avoiding users who didn't rate\n",
    "        out = sae(input_batch)\n",
    "        target.require_grad = False # to avoid get gradient for the targets\n",
    "        out[target == 0] = 0\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)  \n",
    "\n",
    "        testing_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
    "        nb_usr_rated += 1\n",
    "        \n",
    "print(f'The Testing data loss value is: {testing_loss / nb_usr_rated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hope you enjoyed it,  \n",
    "Thanks for reading.  \n",
    "Peace ^_^**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
